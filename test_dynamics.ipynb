{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4452, grad_fn=<MeanBackward1>)\n",
      "tensor(0.1108, grad_fn=<MeanBackward1>)\n",
      "tensor(0.0865, grad_fn=<MeanBackward1>)\n",
      "tensor(0.0868, grad_fn=<MeanBackward1>)\n",
      "tensor(0.0661, grad_fn=<MeanBackward1>)\n",
      "tensor(0.0885, grad_fn=<MeanBackward1>)\n",
      "tensor(0.0507, grad_fn=<MeanBackward1>)\n",
      "tensor(0.0778, grad_fn=<MeanBackward1>)\n",
      "tensor(0.0903, grad_fn=<MeanBackward1>)\n",
      "tensor(0.0467, grad_fn=<MeanBackward1>)\n",
      "tensor(0.0767, grad_fn=<MeanBackward1>)\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "tensor([[-0.0656],\n",
      "        [ 0.9974],\n",
      "        [ 0.9974],\n",
      "        [ 0.9974],\n",
      "        [ 0.5229],\n",
      "        [ 0.9974],\n",
      "        [ 0.9974],\n",
      "        [ 0.0072],\n",
      "        [ 0.9974],\n",
      "        [-0.0139]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "#         self.fc3 = nn.Linear(100, 100)\n",
    "        self.fc4 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "#         x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import numpy as np \n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    model = Encoder().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    model.train()\n",
    "    for itr in range(10000):\n",
    "        x = np.random.uniform(size=(100,2))\n",
    "        y = np.random.uniform(size=(100,2))\n",
    "        targ = (np.linalg.norm(x-y, axis=1) <= 0.4).reshape(-1, 1).astype(np.float32)\n",
    "        attn = model(torch.Tensor(np.concatenate((x, y), axis=1), device=device))\n",
    "#         attn = model(torch.Tensor(np.linalg.norm(x-y, axis=1).reshape(-1, 1), device=device))\n",
    "#         e_x = model(torch.Tensor(x, device=device))\n",
    "#         e_y = model(torch.Tensor(y, device=device))\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.mean(\n",
    "            torch.abs(attn - torch.Tensor(targ, device=device)),\n",
    "        )\n",
    "        if itr % 1000 == 0:\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "    x = np.random.uniform(size=(10,2))\n",
    "    y = np.random.uniform(size=(10,2))\n",
    "    targ = (np.linalg.norm(x-y, axis=1) <= 0.4).reshape(-1, 1).astype(np.float32)\n",
    "    attn = model(torch.Tensor(np.concatenate((x, y), axis=1), device=device))\n",
    "    print(targ)\n",
    "    print(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvin/anaconda3/envs/rl/lib/python3.5/site-packages/ipykernel/__main__.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0092, grad_fn=<MeanBackward1>)\n",
      "tensor(0.0056, grad_fn=<MeanBackward1>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.8579, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.1421, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.8287, 0.1713, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0154, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.9846, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "       grad_fn=<AsStridedBackward>)\n",
      "[[[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvin/anaconda3/envs/rl/lib/python3.5/site-packages/ipykernel/__main__.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes=[2, 20, 20, 1]):\n",
    "        # num_obj_classes includes background class\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            self.add_module('layer_{}'.format(i), self.layers[i])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = F.relu(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "    \n",
    "model = MLP([2, 100, 25])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "for itr in range(1000):\n",
    "    x = np.random.uniform(-1, 1, size=(100, 2))\n",
    "    inds = (2*(x+1)).astype(np.uint8)\n",
    "    targ = np.zeros((100, 5, 5), dtype=np.float32)\n",
    "    for i in range(100):\n",
    "        targ[i,inds[i][0],inds[i][1]] = 1.\n",
    "    out = torch.nn.Softmax()(model(torch.Tensor(x)))\n",
    "    out = torch.reshape(out, (-1, 5, 5))\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.mean(\n",
    "        torch.abs(out - torch.Tensor(targ)),\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss)\n",
    "# tests = []\n",
    "# for x in range(-2, 3):\n",
    "#     for y in range(-2, 3):\n",
    "#         tests.append([x/2.,y/2.])\n",
    "# tests = np.array(tests)\n",
    "# print((2*(tests+1)).astype(np.uint8))\n",
    "x = np.random.uniform(-1, 1, size=(100, 2))\n",
    "inds = (2*(x+1)).astype(np.uint8)\n",
    "targ = np.zeros((100, 5, 5), dtype=np.float32)\n",
    "for i in range(100):\n",
    "    targ[i,inds[i][0],inds[i][1]] = 1.\n",
    "out = torch.nn.Softmax()(model(torch.Tensor(x)))\n",
    "out = torch.reshape(out, (-1, 5, 5))\n",
    "loss = torch.mean(\n",
    "    torch.abs(out - torch.Tensor(targ)),\n",
    ")\n",
    "print(loss)\n",
    "print(out)\n",
    "print(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "data = h5py.File('data/obj_balls.h5', 'r')\n",
    "\n",
    "ims = np.zeros((5, 3, 64, 64), dtype=np.float32)\n",
    "\n",
    "locs = np.where(data['training']['groups'][:1, :5][0] == 2)\n",
    "ims[locs[0], np.zeros_like(locs[3]), locs[1], locs[2]] = 1.\n",
    "\n",
    "locs = np.where(data['training']['groups'][:1, :5][0] == 1)\n",
    "ims[locs[0], 2*np.ones_like(locs[3]), locs[1], locs[2]] = 1.\n",
    "\n",
    "import cv2\n",
    "cv2.imshow('im', (255*ims[0]).astype(np.uint8).transpose([1,2,0]))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9666, grad_fn=<MeanBackward1>) tensor([-0.6943,  0.8889,  0.9955, -0.4030,  1.3577,  1.0361, -0.2839, -0.1639,\n",
      "         0.7220,  0.3152], grad_fn=<SelectBackward>) [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "tensor(0.0566, grad_fn=<MeanBackward1>) tensor([ 0.0053,  0.0049, -0.0154,  0.2577,  0.3687,  0.2930,  0.1761,  0.0571,\n",
      "        -0.0068, -0.1126], grad_fn=<SelectBackward>) [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1001) must match the size of tensor b (1000) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d0bd39425e24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     loss = torch.mean(\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mreconstr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1001) must match the size of tensor b (1000) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes=[1, 100, 100, 100, 2]):\n",
    "        # num_obj_classes includes background class\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            self.add_module('layer_{}'.format(i), self.layers[i])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = F.elu(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "    \n",
    "model = MLP([1, 100, 10])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "for itr in range(1000):\n",
    "    inds = np.random.randint(0, 8, size=1000, dtype=np.uint8)\n",
    "    x = np.zeros((1000, 10))\n",
    "    y = np.zeros((1000, 10))\n",
    "    x[np.arange(1000),inds] = 1\n",
    "    x += np.random.normal(0, 0.1, size=(1000, 10))\n",
    "    y[np.arange(1000),inds+2] = 1\n",
    "    \n",
    "    x_var = Variable(torch.Tensor(x), requires_grad=True)\n",
    "#     reconstr = model(x_var)\n",
    "    reconstr = torch.zeros((1000, 10))\n",
    "    inds = (x_var >= 0.5).nonzero()\n",
    "    reconstr = model(inds[:,1].type(torch.FloatTensor).reshape(-1, 1)) #for objects: reshape, and sum, and reshape again\n",
    "#     shifts = Variable(model(torch.Tensor(np.expand_dims(inds, axis=1))), requires_grad=True)\n",
    "# #     shifts = np.ones((1000, 2))*0.001\n",
    "# #     shifts[:,0] = (inds + 2 - 4.5)/4.5\n",
    "# #     shifts = torch.Tensor(shifts)\n",
    "    \n",
    "# #     m = torch.distributions.Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "# #     samples = m.sample(torch.Size([100]))[:,0]\n",
    "# #     samples *= shifts[:,1]\n",
    "# #     samples += shifts[:,0]\n",
    "# #     samples = torch.clamp(samples, -4.5, 4.498)\n",
    "# #     samples += 4.5\n",
    "# #     reconstr = torch.zeros((100, 10))\n",
    "# #     for i in range(100):\n",
    "# #         reconstr[i].index_fill_(0, torch.floor(samples[i]).type(torch.LongTensor), samples[i]-torch.floor(samples[i]))\n",
    "# #         reconstr[i].index_fill_(0, torch.ceil(samples[i]+0.001).type(torch.LongTensor), torch.ceil(samples[i]+0.001)-samples[i])\n",
    "# #     print(reconstr[0], y[0])\n",
    "#     reconstr = torch.zeros((1000, 10))\n",
    "#     softmax = torch.nn.Softmax()\n",
    "#     for i in range(1000):\n",
    "#         row = torch.zeros(10)\n",
    "#         for j in range(10):\n",
    "#             row[j] = -((j-4.5)/4.5-shifts[i,0])**2 #/ shifts[i,1]\n",
    "#         reconstr[i] = softmax(row)\n",
    "# #         print(reconstr[i])\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.mean(\n",
    "        (reconstr - torch.Tensor(y))**2,\n",
    "    )\n",
    "    loss.backward()\n",
    "#     print(shifts.grad[0, 0])\n",
    "#     print(x_var.grad)\n",
    "    optimizer.step()\n",
    "#     print(loss, (inds[0]+2-4.5)/4.5, shifts[0, 0])\n",
    "    if itr % 100 == 0:\n",
    "        print(loss, reconstr[0], y[0])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1626, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  0.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0685, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0667, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0638, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0634, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0600, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0595, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0565, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0576, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  0.,  1.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0584, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0544, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1.,  0., -0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0374, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0., -0.,  1.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0372, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0., -0.,  1.,  0.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0364, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0344, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0336, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  1., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0293, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  1., -0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0261, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  0., -0.,  1.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0241, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([-0.,  1., -0., -0., -0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0248, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0251, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0255, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0., -0.,  0.,  1.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0246, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0252, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0252, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  1., -0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0264, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  1.,  0., -0., -0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0232, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1., -0., -0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0248, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0., -0.,  0., -0.,  1.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0251, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0247, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  0., -0.,  1.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0250, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  1.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0241, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  1.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0236, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1.,  0.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0223, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0226, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 1., -0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0194, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0., -0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0176, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  1.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0159, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0., -0.,  0.,  1., -0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0120, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  0.,  0.,  0.,  1.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0120, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1., -0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0120, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  1., -0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0119, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  1., -0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0107, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  1.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0112, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  0.,  1., -0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0107, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0., -0.,  0., -0.,  1.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0089, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1., -0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0109, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  1., -0.,  0., -0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0103, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0., -0.,  1., -0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0112, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([-0.,  1.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0105, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  1., -0.,  0., -0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0113, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1.,  0.,  0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0101, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1.,  0.,  0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0092, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  0., -0.,  1., -0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0101, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0., -0., -0.,  1., -0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0093, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  1.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0091, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  0., -0.,  1., -0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0083, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  1., -0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0073, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  1.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0079, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  1., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0065, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  1., -0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0055, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0., -0., -0.,  0., -0.,  1.,  0.], grad_fn=<RoundBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0054, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1.,  0.,  0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0041, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0., -0.,  0.,  0., -0.,  1.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0039, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  1.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0029, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1.,  0.,  0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0027, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1., -0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0025, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0., -0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0021, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0022, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1.,  0.,  0., -0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0018, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0., -0.,  0.,  1., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0014, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0., -0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0015, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0., -0.,  1.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0012, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  0.,  1., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0010, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1.,  0.,  0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0010, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0., -0., -0.,  1., -0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0008, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0., -0., -0.,  0.,  0.,  1.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0008, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([-0., -0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0007, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0., -0.,  0.,  1., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0007, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1.,  0., -0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0006, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([-0.,  1.,  0., -0., -0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0006, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1., -0.,  0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0005, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1., -0.,  0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0005, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1., -0., -0., -0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0004, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  1., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0004, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0., -0.,  0.,  1.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0003, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  1.,  0.,  0., -0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0003, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  1.,  0.,  0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0003, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0., -0.,  0.,  1.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0003, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  0.,  1., -0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0003, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  0., -0.,  1., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0002, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  1.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0., -0., -0.,  1., -0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0002, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0.,  0., -0.,  0.,  1.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0002, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0., -0.,  0.,  0., -0.,  1.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0002, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0., -0.,  1., -0., -0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0001, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0., -0.,  1., -0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0001, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  1.,  0.,  0., -0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0001, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0., -0.,  0.,  1., -0., -0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0001, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  0.,  0.,  0., -0.,  1.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0001, grad_fn=<MeanBackward1>) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward>) tensor([ 0.,  1.,  0., -0., -0.,  0.,  0.,  0.,  0.,  0.], grad_fn=<RoundBackward>)\n",
      "tensor(0.0001, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes=[1, 100, 100, 100, 2]):\n",
    "        # num_obj_classes includes background class\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            self.add_module('layer_{}'.format(i), self.layers[i])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = F.elu(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "mb_size = 1000\n",
    "grid_size = 10 #100\n",
    "max_shift = 2\n",
    "force_size = 1\n",
    "\n",
    "prev_force_model = MLP([1, 10, 10, force_size])\n",
    "wall_force_model = MLP([1, 10, 10, force_size])\n",
    "render_model = MLP([force_size, 100, 2*max_shift+1])\n",
    "optimizer = optim.Adam(list(prev_force_model.parameters()) \n",
    "                       + list(wall_force_model.parameters()) \n",
    "                       + list(render_model.parameters()), lr=0.001)\n",
    "prev_force_model.train()\n",
    "wall_force_model.train()\n",
    "render_model.train()\n",
    "\n",
    "# ind_combs = np.dstack(np.meshgrid(np.arange(100), np.arange(100))).reshape(-1, 2)\n",
    "# ind_combs = ind_combs[:, [1,0]]\n",
    "# ind_combs = torch.Tensor(ind_combs)\n",
    "diff_combs = np.arange(-grid_size+1, grid_size).reshape(-1, 1)\n",
    "diff_combs = torch.Tensor(diff_combs)\n",
    "diff_inds = np.dstack(np.meshgrid(np.arange(grid_size), np.arange(grid_size))).reshape(-1, 2)\n",
    "diff_inds = diff_inds[:, 1] - diff_inds[:, 0] + grid_size - 1\n",
    "diff_inds = torch.Tensor(diff_inds.reshape(-1, 1)).type(torch.LongTensor)\n",
    "\n",
    "shift_mats = []\n",
    "for i in range(grid_size):\n",
    "    shift_mat = np.zeros((2*max_shift+1, grid_size+2*max_shift))\n",
    "    shift_mat[:, i:i+2*max_shift+1] = np.eye(2*max_shift+1)\n",
    "    shift_mats.append(shift_mat)\n",
    "shift_mats = torch.Tensor(np.array(shift_mats))\n",
    "\n",
    "# res = []\n",
    "# for i in range(x.shape[0]):\n",
    "#     res.extend(np.concatenate((np.tile(x[i], (x.shape[0], 1)), x), axis=1))\n",
    "# np.array(res)\n",
    "\n",
    "def reflect_ind(ind, lower, upper):\n",
    "    if ind < lower:\n",
    "        return lower + (lower-ind)\n",
    "    if ind > upper:\n",
    "        return upper - (ind - upper)\n",
    "    return ind\n",
    "reflect_ind = np.vectorize(reflect_ind)\n",
    "\n",
    "for itr in range(10000):\n",
    "    inds = np.random.randint(1+max_shift, grid_size-1-max_shift, size=mb_size, dtype=np.uint8)\n",
    "#     inds = np.random.randint(2*max_shift, grid_size-1-2*max_shift, size=mb_size, dtype=np.uint8)\n",
    "    shifts = np.random.randint(-max_shift, max_shift+1, size=mb_size, dtype=np.int8)\n",
    "    \n",
    "    wall = np.zeros((mb_size, grid_size))\n",
    "    prev = np.zeros((mb_size, grid_size))\n",
    "    cur = np.zeros((mb_size, grid_size))\n",
    "    targ = np.zeros((mb_size, grid_size))\n",
    "    \n",
    "    wall[:,[0, grid_size-1]] = 1\n",
    "    prev[np.arange(mb_size),inds] = 1\n",
    "    cur[np.arange(mb_size),inds+shifts] = 1\n",
    "    targ[np.arange(mb_size),reflect_ind(inds+2*shifts, 1, grid_size-2)] = 1\n",
    "    \n",
    "    wall = Variable(torch.Tensor(wall), requires_grad=True)\n",
    "    prev = Variable(torch.Tensor(prev), requires_grad=True)\n",
    "    cur = Variable(torch.Tensor(cur), requires_grad=True)\n",
    "    targ = Variable(torch.Tensor(targ), requires_grad=False)\n",
    "    \n",
    "    prev_forces = prev_force_model(diff_combs.type(torch.FloatTensor))\n",
    "    wall_forces = wall_force_model(diff_combs.type(torch.FloatTensor))\n",
    "    prev_coefs = (cur.reshape(mb_size, grid_size, 1).repeat(1, 1, grid_size).reshape(mb_size, grid_size*grid_size)\n",
    "        * prev.repeat(1, grid_size).reshape(mb_size, grid_size*grid_size)\n",
    "    )\n",
    "    wall_coefs = (cur.reshape(mb_size, grid_size, 1).repeat(1, 1, grid_size).reshape(mb_size, grid_size*grid_size)\n",
    "        * wall.repeat(1, grid_size).reshape(mb_size, grid_size*grid_size)\n",
    "    )\n",
    "    forces = (\n",
    "        prev_coefs.reshape(mb_size, grid_size*grid_size, 1) \n",
    "        * prev_forces[diff_inds].reshape(1, grid_size*grid_size, force_size)\n",
    "        + \n",
    "        wall_coefs.reshape(mb_size, grid_size*grid_size, 1) \n",
    "        * wall_forces[diff_inds].reshape(1, grid_size*grid_size, force_size)\n",
    "    )\n",
    "    forces = forces.reshape(mb_size, grid_size, grid_size, force_size).sum(dim=2)\n",
    "    \n",
    "    pred_shifts = render_model(forces.reshape(-1, force_size)).reshape(mb_size, grid_size, 2*max_shift+1)\n",
    "    pred_shifts = pred_shifts.permute(1, 0, 2)\n",
    "    pred_shifts = torch.matmul(pred_shifts, shift_mats)\n",
    "    pred_shifts = pred_shifts.permute(1, 0, 2)\n",
    "    render = pred_shifts * cur.reshape(mb_size, grid_size, 1)\n",
    "    render = torch.sum(render, dim=1)\n",
    "    render = render[:, max_shift:max_shift+grid_size]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.mean(\n",
    "        (render - targ)**2,\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if itr % 100 == 0:\n",
    "        print(loss, prev[0], cur[0], torch.round(render[0]))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [1, 2, 3, 0],\n",
       "       [4, 5, 6, 7],\n",
       "       [8, 9, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# data = np.arange(10*4*3*3).reshape(10, 4, 3, 3)\n",
    "x = (np.arange(9)+1).reshape(3, 3)\n",
    "y1 = np.array([\n",
    "    [0,0,0,0, 1,0,0,0, 0,0,0,0, 0,0,0,0,],\n",
    "    [0,0,0,0, 0,1,0,0, 0,0,0,0, 0,0,0,0,],\n",
    "    [0,0,0,0, 0,0,1,0, 0,0,0,0, 0,0,0,0,],\n",
    "\n",
    "    [0,0,0,0, 0,0,0,0, 1,0,0,0, 0,0,0,0,],\n",
    "    [0,0,0,0, 0,0,0,0, 0,1,0,0, 0,0,0,0,],\n",
    "    [0,0,0,0, 0,0,0,0, 0,0,1,0, 0,0,0,0,],\n",
    "    \n",
    "    [0,0,0,0, 0,0,0,0, 0,0,0,1, 0,0,0,0,],\n",
    "    [0,0,0,0, 0,0,0,0, 0,0,0,0, 1,0,0,0,],\n",
    "    [0,0,0,0, 0,0,0,0, 0,0,0,0, 0,1,0,0,]\n",
    "])\n",
    "y2 = np.array([\n",
    "    [0,1,0,0],\n",
    "    [0,0,1,0],\n",
    "    [0,0,0,1],\n",
    "    [0,0,0,0]\n",
    "])\n",
    "(x.reshape(1, -1) @ y1).reshape(4, 4)\n",
    "# data = torch.Tensor(data)\n",
    "# y1 = torch.Tensor(y1)\n",
    "# y2 = torch.Tensor(y2)\n",
    "# data = data.permute(1,0,2)\n",
    "# y = torch.stack((y1, y2), dim=0)\n",
    "# torch.matmul(data, y).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
